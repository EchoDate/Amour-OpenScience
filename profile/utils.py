"""
Utility Functions
"""

from typing import Dict, Any, Optional
from .profile import Profile, StaticTraits, EmotionVector, Relation


def create_profile_from_annotator_data(profile_data: Dict[str, Any]) -> Profile:
    """
    Create Profile object from annotator-generated Profile data
    
    Args:
        profile_data: Profile data generated by annotator, format:
            {
                "gender": "...",
                "age": ...,
                "interests": "...",
                "job": "...",
                "mbti": "...",
                "personality": "...",
                "style": "..."
            }
    
    Returns:
        Profile object
    """
    # Parse age (handle formats like "38岁")
    age_value = profile_data.get("age", 0)
    age = 0
    if isinstance(age_value, int):
        age = age_value
    elif isinstance(age_value, str):
        # Extract numeric part (handle formats like "38岁", "25", etc.)
        import re
        age_match = re.search(r'\d+', age_value)
        if age_match:
            try:
                age = int(age_match.group(0))
            except ValueError:
                age = 0
        else:
            age = 0
    else:
        age = 0
    
    # Create static traits
    static_traits = StaticTraits(
        name=profile_data.get("name", ""),
        gender=profile_data.get("gender", ""),
        age=age,
        occupation=profile_data.get("job", ""),
        interests=profile_data.get("interests", "").split(",") if isinstance(profile_data.get("interests"), str) else profile_data.get("interests", []),
        mbti=profile_data.get("mbti", ""),
        personality=profile_data.get("personality", ""),
        talking_style=profile_data.get("style", "")
    )
    
    # Create default emotion vector (can be initialized based on MBTI)
    emotion_vector = EmotionVector()
    emotion_vector = _initialize_emotion_from_mbti(emotion_vector, static_traits.mbti)
    
    # Create Profile
    profile = Profile(
        static_traits=static_traits,
        emotion_vector=emotion_vector
    )
    
    return profile


def _initialize_emotion_from_mbti(emotion: EmotionVector, mbti: str) -> EmotionVector:
    """
    Initialize emotion vector based on MBTI type
    
    Args:
        emotion: Emotion vector object
        mbti: MBTI type (such as "INTJ", "ENFP", etc.)
    
    Returns:
        Updated emotion vector
    """
    if not mbti or len(mbti) < 4:
        return emotion
    
    mbti_upper = mbti.upper()
    
    # E vs I (Extraversion)
    if mbti_upper[0] == 'E':
        emotion.extraversion = 0.7
    else:
        emotion.extraversion = 0.3
    
    # S vs N (Intuition/Openness)
    if mbti_upper[1] == 'N':
        emotion.openness = 0.7
    else:
        emotion.openness = 0.5
    
    # T vs F (Thinking/Agreeableness)
    if mbti_upper[2] == 'F':
        emotion.agreeableness = 0.7
    else:
        emotion.agreeableness = 0.5
    
    # J vs P (Judging/Conscientiousness)
    if mbti_upper[3] == 'J':
        emotion.conscientiousness = 0.7
    else:
        emotion.conscientiousness = 0.5
    
    return emotion


def extract_agent_id_from_text(text: str) -> Optional[str]:
    """
    Extract Agent ID from text
    
    Args:
        text: Text containing Agent ID
    
    Returns:
        Agent ID or None
    """
    import re
    
    # Try to match common Agent ID formats
    patterns = [
        r'Agent\s+([A-Z])',  # "Agent A"
        r'Character\s+([A-Z])',  # "Character A"
        r'([A-Z])\s+said',  # "A said"
        r'from\s+([A-Z])',  # "from A"
    ]
    
    for pattern in patterns:
        match = re.search(pattern, text, re.IGNORECASE)
        if match:
            return match.group(1)
    
    return None


def detect_interaction_type(text: str, llm_model=None) -> Optional[str]:
    """
    Detect interaction type
    
    If LLM model is provided, use LLM to judge interaction type; otherwise use keyword matching.
    
    Args:
        text: Interaction text
        llm_model: LLM model (optional), if provided use LLM for judgment
    
    Returns:
        Interaction type (such as "criticism", "praise", "conflict", "friendly", "help", "betrayal", etc.) or None
    """
    # If LLM model is provided, use LLM for judgment
    if llm_model is not None:
        return _detect_interaction_type_with_llm(text, llm_model)
    
    # Otherwise use keyword matching (backward compatible)
    return _detect_interaction_type_with_keywords(text)


def _detect_interaction_type_with_keywords(text: str) -> Optional[str]:
    """
    Detect interaction type using keyword matching (backward compatible method)
    
    Args:
        text: Interaction text
    
    Returns:
        Interaction type or None
    """
    text_lower = text.lower()
    
    # Criticism related
    criticism_keywords = ["stupid", "idiot", "wrong", "bad", "hate", "笨蛋", "白痴", "错误", "糟糕"]
    if any(kw in text_lower for kw in criticism_keywords):
        return "criticism"
    
    # Praise related
    praise_keywords = ["good", "great", "excellent", "love", "wonderful", "棒", "优秀", "美好"]
    if any(kw in text_lower for kw in praise_keywords):
        return "praise"
    
    # Conflict related
    conflict_keywords = ["fight", "argue", "disagree", "conflict", "争吵", "争论", "冲突"]
    if any(kw in text_lower for kw in conflict_keywords):
        return "conflict"
    
    # Friendly related
    friendly_keywords = ["thank", "appreciate", "help", "谢谢", "感谢", "帮助"]
    if any(kw in text_lower for kw in friendly_keywords):
        return "friendly"
    
    # Help related
    help_keywords = ["help", "assist", "support", "帮助", "协助", "支持"]
    if any(kw in text_lower for kw in help_keywords):
        return "help"
    
    return None


def _detect_interaction_type_with_llm(text: str, llm_model) -> Optional[str]:
    """
    Detect interaction type using LLM
    
    Args:
        text: Interaction text
        llm_model: LLM model
    
    Returns:
        Interaction type or None
    """
    # Build prompt
    system_message = "You are an expert at analyzing social interactions. Analyze the given text and determine the interaction type."
    
    prompt = f"""Analyze the following interaction text and determine its type.

Text: {text}

Possible interaction types:
- "criticism": Negative feedback, blame, or criticism
- "praise": Positive feedback, compliments, or appreciation
- "conflict": Disagreement, argument, or confrontation
- "friendly": Friendly conversation, greetings, or casual chat
- "help": Offering or requesting help, assistance, or support
- "betrayal": Betrayal, deception, or breaking trust
- None: If the interaction doesn't clearly fit any of the above categories

Respond with ONLY the interaction type (e.g., "criticism", "praise", "conflict", "friendly", "help", "betrayal", or "None").
Do not include any other text or explanation."""

    try:
        # Call LLM
        if hasattr(llm_model, 'generate'):
            success, response = llm_model.generate(system_message, prompt)
            if not success:
                # If LLM call fails, fall back to keyword matching
                return _detect_interaction_type_with_keywords(text)
        else:
            # If LLM model doesn't have generate method, try direct call
            try:
                response = llm_model(prompt)
                success = True
            except Exception:
                # If call fails, fall back to keyword matching
                return _detect_interaction_type_with_keywords(text)
        
        if not success:
            return _detect_interaction_type_with_keywords(text)
        
        # Parse LLM response
        response = response.strip().lower()
        
        # Extract interaction type
        valid_types = ["criticism", "praise", "conflict", "friendly", "help", "betrayal"]
        for interaction_type in valid_types:
            if interaction_type in response:
                return interaction_type
        
        # If response is "none" or similar, return None
        if "none" in response or "null" in response:
            return None
        
        # If unable to parse, fall back to keyword matching
        return _detect_interaction_type_with_keywords(text)
        
    except Exception as e:
        # If any error occurs, fall back to keyword matching
        import warnings
        warnings.warn(f"LLM-based interaction type detection failed: {e}. Falling back to keyword matching.")
        return _detect_interaction_type_with_keywords(text)


def merge_profiles(profile1: Profile, profile2: Profile, weight: float = 0.5) -> Profile:
    """
    Merge two Profiles (for certain scenarios)
    
    Args:
        profile1: First Profile
        profile2: Second Profile
        weight: Merge weight (0-1, 0.5 means average)
    
    Returns:
        Merged Profile
    """
    # Static traits cannot be merged, use profile1's
    merged = Profile(
        static_traits=profile1.static_traits,
        emotion_vector=EmotionVector(
            openness=profile1.emotion_vector.openness * (1-weight) + profile2.emotion_vector.openness * weight,
            conscientiousness=profile1.emotion_vector.conscientiousness * (1-weight) + profile2.emotion_vector.conscientiousness * weight,
            extraversion=profile1.emotion_vector.extraversion * (1-weight) + profile2.emotion_vector.extraversion * weight,
            agreeableness=profile1.emotion_vector.agreeableness * (1-weight) + profile2.emotion_vector.agreeableness * weight,
            neuroticism=profile1.emotion_vector.neuroticism * (1-weight) + profile2.emotion_vector.neuroticism * weight,
            trust=profile1.emotion_vector.trust * (1-weight) + profile2.emotion_vector.trust * weight,
            stress=profile1.emotion_vector.stress * (1-weight) + profile2.emotion_vector.stress * weight,
            energy=profile1.emotion_vector.energy * (1-weight) + profile2.emotion_vector.energy * weight,
        )
    )
    
    # Merge relationships (take union, average values)
    all_agent_ids = set(profile1.relations.keys()) | set(profile2.relations.keys())
    for agent_id in all_agent_ids:
        rel1 = profile1.get_relation(agent_id)
        rel2 = profile2.get_relation(agent_id)
        
        # Merge relationship type: prioritize non-None value, if both have use first one
        merged_relation_type = rel1.relation_type if rel1.relation_type is not None else rel2.relation_type
        
        merged_rel = Relation(
            intimacy=rel1.intimacy * (1-weight) + rel2.intimacy * weight,
            trust=rel1.trust * (1-weight) + rel2.trust * weight,
            dominance=rel1.dominance * (1-weight) + rel2.dominance * weight,
            relation_type=merged_relation_type
        )
        merged.update_relation(agent_id, merged_rel)
    
    return merged

